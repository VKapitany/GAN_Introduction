{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_Intro.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgFkG9-LLJAW",
        "colab_type": "text"
      },
      "source": [
        "## Introduction to regular Generative Adversarial Networks\n",
        "\n",
        "Adapted from: https://www.tensorflow.org/tutorials/generative/dcgan\n",
        "and https://medium.com/ai-society/gans-from-scratch-1-a-deep-introduction-with-code-in-pytorch-and-tensorflow-cb03cdcdba0f"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRKeze3MODJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.compat.v1.keras.backend import clear_session, get_session,set_session\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape, UpSampling2D, Conv2D, MaxPooling2D, LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.datasets.mnist import load_data\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import sys\n",
        "import gc\n",
        "import time\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19oDv_XPO3pM",
        "colab_type": "text"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFRPlZboOEK9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "aca3ffae-32a0-4589-905d-d1cfb11724c5"
      },
      "source": [
        "# Let's load our data (MNIST)\n",
        "(train_images, train_labels), (test_images, test_labels) = load_data()\n",
        "print(np.shape(train_images),np.shape(train_labels),np.shape(test_images),np.shape(test_labels))\n",
        "\n",
        "#Reshape and normalise\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32') # Reshape\n",
        "train_images = (train_images - 127.5) / 127.5 # Normalize the images to [-1, 1]\n",
        "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1).astype('float32')\n",
        "test_images = (test_images - 127.5) / 127.5 # Normalize the images to [-1, 1]\n",
        "\n",
        "# Batch and shuffle the data\n",
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 256\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZWM4v6fO5oC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "c037d349-225e-45c6-c0dc-311e98a3706f"
      },
      "source": [
        "# Let's see some examples \n",
        "plt.figure(1,figsize=(8,4))\n",
        "plt.subplot(121)\n",
        "plt.imshow(train_images[0,:,:,0],cmap='gray')\n",
        "plt.title(train_labels[0])\n",
        "plt.colorbar()\n",
        "plt.subplot(122)\n",
        "plt.imshow(test_images[0,:,:,0],cmap='gray')\n",
        "plt.colorbar()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f380019d4a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38AYtAWvgn4v",
        "colab_type": "text"
      },
      "source": [
        "## ML\n",
        "\n",
        "Introduction:\n",
        "GANs belong to the set of algorithms named **generative models**. These algorithms belong to the field of unsupervised learning, a sub-set of ML which aims to study algorithms that learn the underlying structure of the given data, without specifying a target value. Generative models learn the **intrinsic distribution function of the input data p(x) (or p(x,y)** if there are multiple targets/classes in the dataset), allowing them to generate both synthetic inputs x’ and outputs/targets y’, typically given some hidden parameters.\n",
        "\n",
        "<center><img src=\"https://miro.medium.com/max/1050/1*5rMmuXmAquGTT-odw-bOpw.jpeg\" width=600></center>\n",
        "\n",
        "GAN concept:\n",
        "1. you have a latent space, often a Gaussian distribution, from which you sample randomly. We will call this random sample `noise`, but really it's meant to be a condensed/latent representation of an image. This noise is the input of your `Generator`.\n",
        "2. The generator transforms this noise into an image of the required size, the `generated fake samples`\n",
        "3. You assign labels to these fake images, e.g. 0s, and take a batch of real image samples, to which you assign labels as well, e.g. 1s.\n",
        "4. You pass on the fake and real images to the discriminator, each labelled as Fake [0] or real [1], and **train the discriminator** on these image/label pairs. The discriminator gets better at distinguishing between them.\n",
        "5. Next, you take your fake samples, and assign them to be real/1s. We assign them as real because we want to train the generator to fool the discriminator. You then get the discriminator to predict the value of your fake samples (you aren't training the discriminator, just predicting the fake image samples). The loss we want the generator to optimise is the difference between the 1s and the discriminator predictions. Remember, the discriminator had been previously trained to output 0s, when it sees fake samples. \n",
        "5. So, you **backgropagate the error between your training labels (1s) and training outputs (discriminator prediction) to the generator, to train it's weights.**\n",
        "6. Rinse and repeat.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBTp2Y1CgphN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir gan_images\n",
        "!mkdir gan_models"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3l_yCLe8t6G7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.compat.v1.keras.backend import clear_session, get_session,set_session\n",
        "import gc\n",
        "\n",
        "def reset_keras():\n",
        "    sess = get_session()\n",
        "    clear_session()\n",
        "    sess.close()\n",
        "    sess = get_session()\n",
        "\n",
        "    print(gc.collect()) # if it's done something you should see a number being outputted\n",
        "\n",
        "    # use the same config as you used to create the session\n",
        "    config = tf.compat.v1.ConfigProto()\n",
        "    config.gpu_options.per_process_gpu_memory_fraction = 1\n",
        "    config.gpu_options.visible_device_list = \"0\"\n",
        "    set_session(tf.compat.v1.Session(config=config))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fBkMLltP6mF",
        "colab_type": "text"
      },
      "source": [
        "###The goal of a GAN is formally to play a minimax game between the generator and discriminator:\n",
        "\n",
        "$\\min_{G}\\max_{D}V(D,G) = \\mathbb{E}_{x~p_{data}(x)}[log D(x)] +  \\mathbb{E}_{z~p(z)}[log 1-D(G(z))]$\n",
        "\n",
        "for:\n",
        "- variable function V,\n",
        "-discriminator D,\n",
        "-generator G, \n",
        "-real images x \n",
        "  - sampled from the image distribution of interest, p(x),\n",
        "-and latent variables z\n",
        "  - sampled from the latent distribution of interest, p(z).\n",
        "\n",
        "Note: In this sense, G and D are just functions/transormations, not compiled architectures.\n",
        "\n",
        "Trivially, this simplifies to:\n",
        "\n",
        "**The goal of the discriminator:**\n",
        "\n",
        "$\\max_D= \\frac{1}{m}\\sum_{i=1}^{m}[log(D(x^{(i))}+log(1-D(G(z^{(i)})))]$\n",
        "\n",
        "**The goal of the generator:**\n",
        "\n",
        "$\\min_G = \\frac{1}{m}\\sum_{i=1}^{m}log(1-D(G(z^{(i)})))$\n",
        "\n",
        "for input datapoints $i={1,...,m}$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCisWRMnYs0O",
        "colab_type": "text"
      },
      "source": [
        "### Loss: binary crossentropy\n",
        "We will use binary crossentropy as our loss function, which looks like this:\n",
        "\n",
        "$BCE(v,y)=-\\frac{1}{m}\\sum_{i=1}^{m}[y_i\\cdot log(v_i) + (1 - y_i)(log(1-v_i)]$\n",
        "\n",
        "where $y_i$ are the targets and $v_i$ the outputs, and y and v the corresponding mini-batch of said  targets and outupts (sometimes, BCE is written to include a scaling factor, which I occlude as it's set to 1)\n",
        "\n",
        "**Discriminator**\n",
        "\n",
        "- **Loss for real inputs, and labels = 1:**\n",
        "If we replace $v_i = D(x_i)$ and $y_i = 1 \\forall i$, we get \n",
        "$-\\frac{1}{m}\\sum_{i=1}^{m}[log(D(x^{(i))}]$. This is the loss related to the real images.\n",
        "\n",
        "- **Loss for fake inputs, and labels = 0:**\n",
        "If we replace $v_i = D(G(z_i))$ and $y_i = 0 \\forall i$, we get \n",
        "$-\\frac{1}{m}\\sum_{i=1}^{m}[log(1-D(G(z^{(i)})))]$. This is the loss related to the fake/generator made images.\n",
        "- **Total discriminator loss:** average of the losses for real and fake inputs\n",
        "\n",
        "Note that the BCE is has a negative sign. However, tensorflow minimises BCE; minimising the negative of the loss is equivalent to maximising the loss.\n",
        "\n",
        "**Generator**\n",
        "\n",
        "Rather than minimising $\\frac{1}{m}\\sum_{i=1}^{m}log(1-D(G(z^{(i)})))$, we maximise $\\frac{1}{m}\\sum_{i=1}^{m}log(D(G(z^{(i)})))$, as this provides stronger gradients at the start of training.\n",
        "\n",
        "- **Loss for fake inputs, and labels = 1:**\n",
        "If we replace $v_i = D(G(z_i))$ and $y_i = 1 \\forall i$, we get \n",
        "$-\\frac{1}{m}\\sum_{i=1}^{m}[log(D(G(z^{(i)})))]$. This is the loss related to the fake/generator made images. Again, minimising this is equivalent to maximising its negative (which is our target)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skMaPxzMPDZQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        },
        "outputId": "7a783bf5-340e-43ca-bcf8-e0e11112dbb4"
      },
      "source": [
        "noise_shape = 100\n",
        "\n",
        "#Architectures\n",
        "\n",
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(noise_shape,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "    assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 7, 7, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 14, 14, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "    return model\n",
        "\n",
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
        "                                     input_shape=[28, 28, 1]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "\n",
        "    return model\n",
        "\n",
        "generator = make_generator_model()\n",
        "discriminator = make_discriminator_model()\n",
        "\n",
        "generator.summary()\n",
        "discriminator.summary()\n",
        "\n",
        "#Losses\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "#Optimizers    \n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 12544)             1254400   \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 12544)             50176     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose (Conv2DTran (None, 7, 7, 128)         819200    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 14, 14, 64)        204800    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 1)         1600      \n",
            "=================================================================\n",
            "Total params: 2,330,944\n",
            "Trainable params: 2,305,472\n",
            "Non-trainable params: 25,472\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 14, 14, 64)        1664      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 7, 7, 128)         204928    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 6273      \n",
            "=================================================================\n",
            "Total params: 212,865\n",
            "Trainable params: 212,865\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eN2KeZGod6Vv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 100\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "# We will reuse this seed overtime (so it's easier)\n",
        "# to visualize progress in the animated GIF)\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_shape])\n",
        "# x = np.linspace(-2, 2, 8)\n",
        "# y = np.linspace(-2, 2, 8)\n",
        "# xv, yv = np.meshgrid(x, y)\n",
        "# xv = xv.reshape(8,8,1)\n",
        "# yv = yv.reshape(8,8,1)\n",
        "# z = np.concatenate((xv,yv),axis=2)\n",
        "# seed = z.reshape(8*8, 2)\n",
        "\n",
        "# checkpoint_dir = 'gan_models/training_checkpoints'\n",
        "# checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "# checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "#                                  discriminator_optimizer=discriminator_optimizer,\n",
        "#                                  generator=generator,\n",
        "#                                  discriminator=discriminator)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKPuMHKGd4T3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Notice the use of `tf.function`\n",
        "# This annotation causes the function to be \"compiled\".\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([BATCH_SIZE, noise_shape])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "\n",
        "      real_output = discriminator(images, training=True)\n",
        "      fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "      gen_loss = generator_loss(fake_output)\n",
        "      disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    return gen_loss, disc_loss"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RmdVsmvhPxyy",
        "colab": {}
      },
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(4,4))\n",
        "  plt.suptitle('Epoch {}'.format(epoch))\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.savefig('gan_images/img{}.png'.format(epoch)) #so it's a continuous stream of images\n",
        "  plt.show()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sr1hOUoEXe-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen_loss_log = []\n",
        "disc_loss_log = []\n",
        "\n",
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      gen_loss, disc_loss = train_step(image_batch)\n",
        "      # Log the generator and discriminator losses, for analysis later\n",
        "      gen_loss_log.append(gen_loss)\n",
        "      disc_loss_log.append(disc_loss)\n",
        "    # Produce images for the video as we go\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator,\n",
        "                             epoch + 1,\n",
        "                             seed)\n",
        "\n",
        "    # Save the model every 50 epochs\n",
        "    if (epoch + 1) % 50 == 0:\n",
        "      #checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "      generator.save('gan_models/gen{}.h5'.format(epoch+1))\n",
        "      discriminator.save('gan_models/dis{}.h5'.format(epoch+1))\n",
        "\n",
        "    print ('Loss generator {}, loss discriminator {}'.format(gen_loss, disc_loss))\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "  # Generate after the final epoch\n",
        "  display.clear_output(wait=True)\n",
        "  generate_and_save_images(generator,\n",
        "                           epochs,\n",
        "                           seed)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GaHjVtNh__8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "80bf8e13-2e9c-4e75-e315-0aa64edd3477"
      },
      "source": [
        "reset_keras()\n",
        "train(train_dataset, EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "423\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdeAzIycDJCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot history of loss during training\n",
        "plt.plot(gen_loss_log, label = 'generator loss')\n",
        "plt.plot(disc_loss_log, label = 'discriminator loss')\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('BCE')\n",
        "plt.title('Loss during training')\n",
        "plt.savefig('training_loss.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHAC6kQaqPYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check what happens with a smooth transition along the latent space input\n",
        "\n",
        "x = np.linspace(-2, 2, 16)\n",
        "y = np.linspace(-2, 2, 16)\n",
        "xv, yv = np.meshgrid(x, y)\n",
        "xv = xv.reshape(16,16,1)\n",
        "yv = yv.reshape(16,16,1)\n",
        "z = np.concatenate((xv,yv),axis=2)\n",
        "z = z.reshape(16*16, 2)\n",
        "\n",
        "predictions = generator(z, training=False)\n",
        "\n",
        "fig = plt.figure(figsize=(16,16))\n",
        "\n",
        "for i in range(predictions.shape[0]):\n",
        "    plt.subplot(16, 16, i+1)\n",
        "    plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.savefig('smooth_transition.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6e0oY0LptMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pK2XERc9t451",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}